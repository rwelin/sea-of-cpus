\documentclass[a4paper,twoside,11pt]{article}
\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage[british]{babel}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{pdflscape}
\usepackage{tikz}

\usepackage[
  style=apa,
  backend=biber,
  urldate=iso8601]{biblatex}
\addbibresource{sources.bib}
\bibliography{sources}
\DeclareLanguageMapping{british}{british-apa}

% Setup source code listings
\usepackage{courier}
\linespread{1.15}

\usepackage{color}
\definecolor{cred}{rgb}{0.9,0.1,0.25}
\definecolor{cgreen}{rgb}{0.05,0.5,0.1}
\definecolor{ccyan}{rgb}{0.1,0.6,0.8}
\definecolor{cmagenta}{rgb}{0.7,0.1,0.2}
\definecolor{cyellow}{rgb}{0.7,0.4,0}
\definecolor{cgray}{rgb}{0.5,0.5,0.5}
\definecolor{clightlightgray}{gray}{1.0}
\def\fpgamodel{xc7v585tffg1761-2}

\usepackage{listings}
\lstset{
  language={[x86masm]Assembler},
  basicstyle=\footnotesize\ttfamily,    % Standardschrift
  tabsize=4,                            % Groesse von Tabs
  extendedchars=true,                   %
  breaklines=true,                      % Zeilen werden Umgebrochen
  frame=b,
  backgroundcolor=\color{clightlightgray},
  %backgroundcolor=\color{cgray},
  keywordstyle=\color{cmagenta}\bfseries,
  stringstyle=\color{cyellow},
  commentstyle=\color{cgreen},
  showspaces=false,                     % Leerzeichen anzeigen ?
  showtabs=false,                       % Tabs anzeigen ?
  xleftmargin=17pt,
  framexleftmargin=17pt,
  framexrightmargin=5pt,
  framexbottommargin=4pt,
  showstringspaces=false                % Leerzeichen in Strings anzeigen ?
}

\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}
{\colorbox[cmyk]{0.43,0.35,0.35,0.01}{\parbox{\textwidth}{\hspace{15pt}#1#2#3}}}
\captionsetup[lstlisting]{ format=listing,
  labelfont=white,
  textfont=white,
  singlelinecheck=false,
  margin=0pt,
  font={bf,sf,small}
}

\def\name{Robert Welin}
\def\prjtitle{Sea-of-CPUs on an FPGA}
\def\cid{00656261}

% Title info
\markboth{}{\name: \prjtitle}

\begin{document}

\begin{titlepage}
% \newgeometry{top=25mm,bottom=25mm,left=38mm,right=32mm}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt}
% \fontfamily{phv}\selectfont

{
\Large
\raggedright
Imperial College London\\[17pt]
Department of Electrical and Electronic Engineering\\[17pt]
Final Year Project Report 2014\\[17pt]

}
\rule{\columnwidth}{3pt}

\vfill

\centering
% \includegraphics[width=0.7\columnwidth,height=60mm,keepaspectratio]{imgs/MyRobot.jpg}

\vfill

\setlength{\tabcolsep}{0pt}
\begin{tabular}{p{40mm}p{\dimexpr\columnwidth-40mm}}
Project Title: & \textbf{\prjtitle} \\[12pt]
Student: & \textbf{\name} \\[12pt]
CID: & \textbf{00656261} \\[12pt]
Course: & \textbf{EIE4} \\[12pt]
Project Supervisor: & \textbf{Dr D.B. Thomas} \\[12pt]
Second Marker: & \textbf{Dr K. Nikolic} \\
\end{tabular}
\end{titlepage}

\section*{Acknowledgements}

I would like to thank my supervisor Dr David Thomas for all his help throughout this project. 

\newpage

\begin{abstract}
This project concerns the design and implementation of a large, configurable
array of independent soft processors on an FPGA with inter-core communication.
The aim of this project is to create a general purpose CPU that utilizes the
dedicated logic, block RAMs, DSP slices of the target Xilinx FPGA well; to
create an interface between the CPUs that allows for communication
between CPUs in different clock regions and to create an assembler in order to
more easily program the device. By designing a very regular instruction set
architecture which was greatly influenced by the target hardware, the resulting
micro-architecture implementation was reasonably small, yet powerful in certain areas. It also allowed for
a very simple assembler. The inter-core communication was implemented using a
FIFO based approach which allowed for straight-forward configuration and high
bandwidth. The CPUs were tested using various programs, demonstrating good
functionality. It was, however, shown that resulting processor was not small enough to properly utilize the FPGA resources efficiently and that the FIFO based communication did not scale well. This resulted in rapidly decreasing clock rate with increasing number of cores and more complex topologies. Possible future improvements to the CPU are considered.
\end{abstract}

\newpage

\tableofcontents

\newpage

\section{Introduction}

FPGAs have for a long time been a desirable platform because of their excellent flexibility and relatively good performance.
Over the last few year, however, the demand for special purpose hardware primitives on the FPGA for ubiquitous operations such as multiply-accumulate has increased rapidly.
Modern FPGAs have therefore become increasingly complex, with large amounts of traditional configurable logic, RAM blocks and dedicated DSP units.

The aim of the project is to design and implement a small, independent soft processor that utilise these resources.
A large number of these CPUs should be instantiated on a single FPGA, forming a large processor array that can co-operate to solve larger, parallel tasks.
An array of this kind could be very useful in field such as image processing, cryptography and video compression.

\section{Background}

\subsection{DSP48E1 Slice}

Figure \ref{fig:dsp48e1} shows a diagram of the embedded Xilinx DSP48E1 slice.
It can perform a large number of different arithmetic and logic operations and is configurable on a per-cycle basis.

The block consists of three main parts: the pre-adder, the multiplier and the ALU.
It has four main data inputs: A (30 bits), B (18 bits), C (47 bits) and D (25 bits), three configuration inputs that control the ALU (ALUMODE), the inputs to the ALU (OPMODE) and the function of the pre-adder and multiplier inputs (INMODE) and one main data output P (47 bits).
The pre-adder allows for two of the data inputs (A and D) to be added or subtracted before the resulting signal enters the multiplier.
The multiplier performs a multiplication on the output of the pre-adder and the B input.
The final stage in the DSP slice is the ALU which can take a number of different inputs and perform addition, subtraction and various logic operations.
The inputs include the C input, the output of the multiplier, inputs A and B concatenated and the previous result of the ALU.
All these inputs and operations are configurable on every clock cycle which makes it a very flexible hardware block. \parencite{dsp48e1}


\begin{figure}
  \centering
  \caption{Diagram of the DSP48E1 slice \parencite[pp 8]{dsp48e1}}
  \label{fig:dsp48e1}
  \includegraphics[width=\linewidth]{dsp48e1}
\end{figure}

\subsection{Block RAM}

Figure \ref{fig:bram} shows a diagram of the Xilinx 36kb block RAM.
The block RAM can be configured in many ways, including the word size and memory width, different port configurations (e.g. single port, true dual port) and clock inputs.

\begin{figure}
  \centering
  \caption{Diagram of the 36kb block RAM \parencite[pp 14]{memory}}
  \label{fig:bram}
  \includegraphics[width=0.5\textwidth]{bram}
\end{figure}

\subsection{Related work}

FPGAs have historically been used for accelerating algorithms by creating custom pipelined, parallel processors, often called hard-core processors.
However, many programs are more suited for software implementations, and it has therefore become more and more common to use soft-core processors along with the accelerator hardware or standalone.
Many commercial soft-processors are available including the Xilinx PicoBlaze microcontroller \parencite{picoblaze}, the Xilinx MicroBlaze \parencite{microblaze} and the Altera Nios II processor \parencite{nios2}.

In research, many different kinds of soft processors have been proposed.
These include multithreaded processors such as \parencite{octavo-2012} and \parencite{custard} which has automatically generated custom instructions.
Various VLIW processors have also been developed such as \parencite{vliw} which has runtime configurable number of issue slots.
Vector processors have also been attempted multiple times \parencite{ultra-fine-2009}\parencite{vespa}.

With the recent addition of special purpose hardware such as the Xilinx DSP48E1 slice, research into soft-processors that utilise these resources has become increasingly popular.
\cite{cheah2012lean} created a small processor that showcased the capabilities of a single DSP slice.
They later developed this into a complete processor \parencite{idea-2012}.

There has also been research into multicore architectures such as \parencite{mora-2009} and \parencite{fpga-simd}.
However, only the latter takes advantage of embedded DSP blocks.

\subsection{Instruction set architectures}

The instruction set architecture (ISA) of a processor can be considered the software interface of the processor.
It provides the programmer or compiler writer a definition of commands that can be issued to the machine, so called opcodes or machine instructions.
The ISA also describes the structure of these opcodes such as length and the information contained in the opcode.
This could be the registers used in the operation, memory locations or specific addressing modes. \parencite[pp 22]{comp-arch-organization}

ISAs are generally divided into two big classes: complex instruction set computer (CISC) and reduced instruction set computer (RISC).
CISC usually features variable length instructions with complex effects, whereas RISC architectures has fixed length instructions with a single effect.
Modern CISC architectures such as x86 are known for being relatively simple to program at the cost of larger, more complex hardware.
Conversely, RISC designs such as MIPS are very small, but require more machine instructions to accomplish the same task as a CISC architecture, resulting in larger programs and a more complex compilers.

Both types of processors usually follow the same architectural pattern with the following four stages:

\begin{enumerate}
    \item \emph{Instruction decode} -- load instruction word from memory and identify the operation and any associated operands.
    \item \emph{Data fetch} -- use the operands of the instruction to fetch any data needed to perform the desired calculation.
    \item \emph{Execution} -- perform the arithmetic or other operation on the fetched data.
    \item \emph{Write back} -- store the result from the execution stage.
\end{enumerate}

In addition, instruction set architectures are further classified by how data is fetched and executed upon.

\begin{itemize}
    \item \emph{Accumulator architecture} -- uses a single register that stores intermediate results.
    \item \emph{Load/store architecture} -- data is fetched from main memory into registers.
        Arithmetic and logic operations only operate on registers.
        This type is very common among RISC architectures such as MIPS and ARM \parencite[pp 9-12]{flynn1995computer}.
    \item \emph{Register memory architecture} -- operands can be used as memory addresses in order to fetch data from main memory and perform the operation on the data directly,
        without having to store the data in a register first.
        The x86 architecture is a well known register memory architecture \parencite[pp 9-12]{flynn1995computer}.

\end{itemize}



\subsubsection{Addressing modes}

When accessing data from memory, a memory address has to be encoded in the machine instruction.
Addressing modes are descriptions of how the operands in a given machine instruction are used to calculate a memory address.
There are several commonly used addressing modes, each with their advantages and disadvantages.

\begin{itemize}
    \item \emph{Absolute addressing} uses an operand in the instruction word as a direct address without any modification.
      This mode usually requires an operand that is large enough to cover the entire address space of the processor,
      which might be impossible for ISAs with very short instruction words.

    \item \emph{Register indirect addressing} uses an operand as a register index.
      The content of the register is then used as a memory address.

    \item \emph{PC relative addressing} calculates an address from adding a constant to the value of the program counter.
      Since computer programs have a lot of spacial locality, 90\% of all branches can be calculated using PC relative addressing and an offset of as little as 8 bits \parencite{isa-design-1995}.

\end{itemize}

\subsection{Micro architectures}

The microarchitecture of a processors refers to a specific implementation of an instruction set architecture.
Although an instruction set architecture can be implemented in more than one microarchitecture, the two are closely related.
Since the aim of this project is to effectively utilise the hardware on the FPGA, the microarchitecture is very influential on the resulting ISA.



%- Other attempts at soft-processors
%  - Microblaze, picoblaze
%  - SIMD processors
%  - DSP block focused processors
%- MPPAs


\section{Design and implementation}

The design had of the processor had to take several aspects into account.

\begin{itemize}
    \item As it was going to be target on an FPGA, the dedicated logic in the form of block RAMs and DSP slices had to be used effectively.
    \item The implementation had to a relatively few number of LUTs in order to accommodate for the ratio between LUTs and other dedicated logic.
    \item The processor had to run at a relatively high clock frequency.
    \item It had to have an instruction set that allowed for good performing DSP programs such as FIR filters, but also allowed for more general computations.
\end{itemize}


%- Proof of concept processor:
%  - Arithmetic instructions that prove points
%  - useful branch instructions and mov

\subsection{Instruction set architecture}

The first constraint on the instruction set architecture was the size of the instruction word.
Since a single block RAM was going to be used as main memory, the instruction word had to be a possible word width of the RAM in order utilise it efficiently.
Three different block RAM configurations were considered: 1024$\times$36, 2048$\times$18 and 4096$\times$9.

\begin{itemize}
  \item 4096$\times$9 -- very small instruction word that would make it difficult to encode the instructions.
  \item 1024$\times$36 -- too small address space which would make it difficult to store both the program and data.
  \item 2048$\times$18 -- middle-ground that has a large enough instruction word and an adequate address space.
\end{itemize}

An 18-bit word size was chosen since the alternatives would result in a too small instruction word or a too small address space.
This size allows for six bits for the opcode and twelve bits for the operands.
These twelve bits could be used for three 4-bit register indices, two 6-bit register indices or some combination of register indices and constants.
Four bits for the register index would allow for a register file with only 16 entries, so a 6-bit register index or equivalently a 64 entry register file was chosen.

The register file was chosen to be 18 bits wide to keep it consistent with the main memory.

In addition to the register file a 47-bit accumulator was added to the design in order to take advantage of the full width of the DSP block.
A large result could alternatively be cropped down to the 18 bits of the register file and memory, but keeping the full result adds the flexibility for the programmer and makes it possible to store the result in three registers or memory locations if necessary.
Also since only two operands can be encoded in the instruction word, the accumulator adds an extra implicit operand which makes it possible to utilise three of the four DSP block inputs.

The different instruction types of the instruction set architecture are shown in table \ref{t:instruction-types}.

\begin{table}
\centering
\caption{Instruction types}
\label{t:instruction-types}
\newcommand{\const}{\multicolumn{2}{c|}{const}}
\begin{tabular}{| l | l | l | l | l |}
    \hline
    Type    & \multicolumn{3}{c|}{Format}  & Example instruction     \\ \hline
            & [17:12]   &   [11:6]  &   [5:0]   &           \\ \hline
    1       & op        &   -       &   -       &   Nop     \\ \hline
    2       & op        &   \const              &   Unconditional absolute jump \\ \hline
    3       & op        &   reg     &   -       &   Move register to accumulator \\ \hline
    4       & op        &   -       &   reg     &   Add register to accumulator \\ \hline
    5       & op        &   reg     &   reg     &   Multiply-accumulate \\ \hline
    6       & op        &   reg     &   const   &   Register increment \\ \hline
\end{tabular}
\end{table}

\subsection{Initial designs}

A key difference between processors is the placement of the main memory in relation to the ALU in the pipeline.
In the beginning, a design heavily inspired by the MIPS architecture was considered and can be seen in figure \ref{core-1}.

It has the same
execution stages: instruction fetch, instruction decode and register read,
execution, memory read/write, register write-back. This processor can support
absolute immediate addressing, PC-relative addressing and register indirect
addressing for memory accesses.

An alternative to this design swaps the position of the data memory and the DSP
in the pipeline. This results in a few differences. Only absolute addressing and register indirect
addressing is available for both data and branches. However, the design supports ALU
instructions that operate directly on data from the block RAM. This is useful
useful for implementing FIR filters for example.
This design can be seen in figure \ref{core-2}.

\begin{landscape}
\begin{figure}
    \caption{Initial processor design.}
    \label{core-1}
    \resizebox{\linewidth}{!}{\input{core-1.tex}}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
    \caption{Initial memory first processor design.}
    \label{core-2}
    \resizebox{\linewidth}{!}{\input{core-2.tex}}
\end{figure}
\end{landscape}

The second one was chosen, due to the advantage of execution direct on memory without having to load data into a register first.

Both these processors had a register file with three read ports and one write port.
Even though only two registers could be addressed from the instruction word, the third read port was considered to be used for other special purpose registers such as a stack pointer or  subroutine return addresses.
The reason behind this type of register file was because of the special SLICEM distributed memory on the FPGA.
This slice can be configured as a 64$\times$1-bit register file with three read ports and one read/write port, using only four LUTs.
The register file was thus implemented by explicitly instantiating 18 of these RAMs, creating a 64$\times$18-bit register file.
This was removed in the final design since the same functionality could be achieved with only two read ports.
An inferred two read port one write port register file also used 25 logic elements than the SLICEM implementation.

The pipeline registers that circumvented the DSP block in order to achieve \texttt{mov} instructions from the register file were also removed by using the registers inside the DSP block instead.

\subsection{Additions to initial design}

The final instruction set of the processor is shown in table \ref{t:instruction-set} and figure \ref{fig:core-IV} shows a block digram of the final implemented design.
The processor at its core a RISC architecture, but has some elements of CISC as well since it has arithmetic instructions that operate directly on memory.

One addition to the initial design is the logical shift right path that goes along the DSP block.
This separate compute path was added since the DSP block can only perform 17-bit shifts and a more flexible shift is necessary for fixed point FIR filters.

Another important addition was the special \texttt{CMAC} instruction which allows for multiply-accumulate operation that does one MAC operation per cycle with a four cycle setup delay.
This takes full advantage of the capabilities of the DSP block.
The operation is implemented by using special purpose registers that keep track of the starting location of an array of filter coefficients (\texttt{coefa}) and the head of a circular buffer (\texttt{dataa}).
The circular buffer is implemented in hardware is simply an offset (\texttt{datao}) that is incremented every cycle during the \texttt{CMAC} operation and wraps around to zero when it reaches the size of the buffer.
At the start of the \texttt{CMAC} operation, the coefficient address and the data address plus the offset are loaded into the registers that will serve as the input addresses of the block RAM. 
This size is also stored in a special register.
During this instruction the program counter is frozen and the memory port that is normally used for instruction fetch is used as the read port of the coefficient array.
A stripped down diagram of the Core during the \texttt{CMAC} instruction can be seen in figure \ref{fig:core-cmac}.

A special instruction for writing to the circular buffer was also added in order to conveniently added new data to the array.
This instruction decrements the offset register and writes the contents of a normal register to the corresponding memory location.

\subsection{Inter-core communication}

Two idea for communication between cores were explored: a shift-register based approach and a FIFO based approach.
Using shift-registers as inputs would allow a processor to be statically connected to another processor and write up to one word per cycle.
A valid bit would indicate whether a specific word had been written to be the sending processor.
During a read, the receiving processor would then wait for the first valid piece of data to arrive at the head of the shift-register.

This approach was decided against since it would require extremely precise timing between processors and would therefore make multi-core programming very difficult.
Instead the FIFO based approach was chosen.
Xilinx CORE generator tool can generate various FIFO configurations of different depth and width and clock configurations.
Since the processors should be able to communicate across different clock regions, an asynchronous FIFO was chosen with independent read and write clocks.

Additional logic was added to select to read from or write to a specific input or output from an array of FIFOs.
The implementation is generic and only requires a change of a constant to change the number of FIFOs that belong to the Core.
This makes it very convenient to change the number of inputs and outputs without much effort.

The software primitives for sending and receiving data from another processor are the \texttt{movfr} and \texttt{movrf} instructions, respectively.
These instructions allow the programmer to either send the value of a register onto a specific output or store the head of a given FIFO in a register.
If a send instruction is issued, but the target FIFO is full, the processor halts until there is room to write.
Similarly, if a receive instruction is issued, but the input FIFO is empty, the processor halts until there is something to read.
Listings \ref{lst:ping} and \ref{lst:pong} shows two programs that when put on two connected processors would pass a value between themselves, decrementing the value before sending it back.

\begin{table}
\centering
\caption{Instruction set}
\label{t:instruction-set}
\newcommand{\const}{\multicolumn{2}{c|}{const}}
\begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{3}{|c|}{Format}        &   Description             \\ \hline
    [17:12]     &   [11:6]  &   [5:0]   &                           \\ \hline
    nop         &   -       &   -       &   Does nothing            \\ \hline
    mova        &   \const              &   acc := const            \\ \hline
    movar       &   ra      &   -       &   acc := ra               \\ \hline
    movra       &   ra      &   -       &   ra := acc               \\ \hline
    movr        &   ra      &   const   &   ra := const             \\ \hline
    movrr       &   ra      &   rb      &   ra := rb                \\ \hline
    lda         &   \const              &   acc := [const]          \\ \hline
    sta         &   \const              &   [const] := acc          \\ \hline
    ldar        &   ra      &   -       &   acc := [ra]             \\ \hline
    star        &   ra      &   -       &   [ra] := acc             \\ \hline
    ldrr        &   ra      &   rb      &   ra := [rb]              \\ \hline
    strr        &   ra      &   rb      &   [ra] := rb              \\ \hline
    shfta       &   \const              &   acc := acc \textgreater\textgreater const \\ \hline
    shftar      &   ra      &   -       &   acc := acc \textgreater\textgreater ra \\ \hline
    adda        &   \const              &   acc := acc + const      \\ \hline
    suba        &   \const              &   acc := acc - const      \\ \hline
    addar       &   ra      &   const   &   ra := ra + const        \\ \hline
    subar       &   ra      &   const   &   ra := ra - const        \\ \hline
    addr        &   ra      &   rb      &   ra := ra + rb           \\ \hline
    subr        &   ra      &   rb      &   ra := ra - rb           \\ \hline
    addrm       &   ra      &   rb      &   ra := ra + [rb]         \\ \hline
    subrm       &   ra      &   rb      &   ra := ra - [rb]         \\ \hline
    mulr        &   ra      &   const   &   ra := ra * const        \\ \hline
    mulrr       &   ra      &   rb      &   ra := ra * rb           \\ \hline
    mulrm       &   ra      &   rb      &   ra := ra * [rb]         \\ \hline
    mac         &   ra      &   rb      &   acc := acc + ra * [rb]  \\ \hline
    macp        &   ra      &   rb      &   acc := p + ra * rb      \\ \hline
    macpm       &   ra      &   rb      &   acc := p + ra * [rb]    \\ \hline
    coefa       &   \const              &   coefa := const          \\ \hline
    dataa       &   \const              &   dataa := const          \\ \hline
    datao       &   \const              &   datao := const          \\ \hline
    datam       &   \const              &   datam := const          \\ \hline
    cmac        &   -       &   -       &   acc := p + [coefa++] * [dataa++] \\ \hline
    cstr        &   ra      &   -       &   datao := (datao-1) mod (datam+1); [dataa+datao] := ra \\ \hline
    j           &   \const              &   pc := const             \\ \hline
    br          &   -       &   rb      &   pc := rb                \\ \hline
    bz          &   ra      &   rb      &   if $ra = 0$: pc := rb     \\ \hline
    bnz         &   ra      &   rb      &   if $ra \neq 0$: pc := rb    \\ \hline
    bnzd        &   ra      &   rb      &   if $ra \neq 0$: pc := rb; ra := ra - 1 \\ \hline
    bltz        &   ra      &   rb      &   if $rb < 0$: pc := rb     \\ \hline
    bgez        &   ra      &   rb      &   if $rb \ge 0$: pc := rb    \\ \hline
    call        &   ra      &   rb      &   ra := pc + 7; pc := rb  \\ \hline
    movrf       &   ra      &   index   &   push back ra to output[index] \\ \hline
    movfr       &   ra      &   index   &   pop front of input[index] \\ \hline
\end{tabular}
\end{table}

Table \ref{t:instruction-delay-slots} shows the number of cycles that has to pass before the result of an instruction is available.
Multiplication instructions take one cycle longer to complete due to the architecture of the DSP48E1 slice (and a slight oversight of a certain use of the INMODE control).
As seen in figure \ref{fig:dsp48e1}, when the multiplier is used, the result goes through the M register, but when it is not used it is bypassed, making the operation one cycle shorter.
This was accommodated for by adding another pipeline register at the C input that could be bypassed if the instruction was a non-multiply operation.
Additional logic to delay the write-back stage also had to be added.

\begin{table}
\centering
\caption{Number of delay slots for different instruction types. Delay slots is the number of cycles that have to pass from the instruction fetch of one instruction until the result is produced or it has taken effect. One delay slot means that an instruction can use the result of preceding instruction immediately.}
\label{t:instruction-delay-slots}
\begin{tabular}{| l | l |}
    \hline
    Instruction type    &   Delay slots     \\ \hline
    Multiplication      &   10              \\ \hline
    Other arithmetic    &   9               \\ \hline
    Jump                &   7               \\ \hline
    CMAC register operations (dataa, datao, datam, coefa) & 1   \\ \hline
\end{tabular}
\end{table}

\begin{landscape}

\begin{figure}
    \caption{Core diagram. The instruction memory and the data memory are different ports on the same block RAM.}
    \label{fig:core-IV}
    \resizebox{1.05\linewidth}{!}{\input{core-IV.tex}}
\end{figure}

\begin{figure}
    \caption{CMAC configuration}
    \label{fig:core-cmac}
    \resizebox{\linewidth}{!}{\input{core-cmac.tex}}
\end{figure}

\end{landscape}

\subsection{Detailed description of pipeline operation}

Below follows a description of the pipeline during normal operation (no multiplication instruction or \texttt{CMAC}).
The list number refers to the pipeline stage.

\begin{enumerate}
  \item The read from the instruction memory is initiated. Program counter is incremented or set to a branch address.
  \item The instruction word is read.
  \item The instruction word is decoded and all control flags are set.
  \item Data is fetched from the register file and accumulator.
  \item The processor determines if a branch will occur two cycles. Data read/write is initiated.
  \item Data is fetched from the data memory or written to.
  \item The inputs to the DSP block are determined and the shift operation is performed. Branch occurs.
  \item The DSP data and control inputs are set.
  \item DSP computing.
  \item Ditto.
  \item Output data is read from the DSP block.
  \item Register/accumulator write-back occurs.
\end{enumerate}

\subsection{Tools}

\subsubsection{Build system}

The build system of the project consists of a number of \texttt{make} scripts that allows for automatic compilation of assembly programs and automated testing of the Core and its components.

\subsubsection{Opcode generator}

In order to keep the opcodes of the instruction words consistent between the assembler and the instruction decode of the core,
an opcode generator script called \texttt{opcode\_vhdl\_gen} was implemented to generate opcodes automatically from a list of instruction mnemonics.
From the list of mnemonics, the script generates a VHDL package with opcode constants that can then be used by the rest of the processor.
Only the first word on each line is used as a mnemonic, the rest is added as a comment to the constant in the VHDL package.
This list of instructions is used by both the assembler and the opcode generator, which guarantees that the opcodes are consistent between the assembler and the instruction decode.
The script also makes it more convenient to change the instruction set without having to edit the assembler.

Listing \ref{lst:instruction-set-txt} shows a subset of the Core's instruction set in this format and listing \ref{lst:instruction-set-vhdl} shows the corresponding VHDL package generated by \texttt{opcode\_vhdl\_gen}.



\subsubsection{Assembler}

In order to make it easier to program the device, a simple assembler was created.
The assembly language features instruction mnemonics, register names, signed decimal constants, labels and comments.
Labels make it easier to write branch instructions and add static data.
The assembler does two passes on the assembly code: the first to translate labels to memory addresses and the second to generate the machine code.
The program outputs a VHDL package containing an array of machine instructions.
This output was chosen because in would allow for easy usage in the simulations.

\subsubsection{Test template generator}

Automated testing was used in order to ensure correct execution of the processor and its components.
This was achieved by implementing a test template generator, called \texttt{mktest}.
The program takes a VHDL entity and outputs a corresponding test template.
Inputs and expected outputs could then be added to the template and when run as a simulation, would automatically fail on incorrect output.
This method ensured faster refactoring and the test files also serve as a guarantee of the components behaviour.

Listing \ref{lst:test-template} shows the template generated for the Core entity.

\subsubsection{Array generator}

Due to the Xilinx tools lack of support for versions of VHDL later than VHDL 1993, a program had to be written in order to generate large configurations of processor cores.
The resulting program, called \texttt{mkarray}, takes a topology and a size as arguments and outputs a VHDL entity.
The entity instantiates the given number of cores, connected according to the given topology.
The entity uses the same interface as the core itself, but leaves the FIFO signals unconnected for the user to connect.

Four configurations were implemented: a one directional chain, a bi-directional chain, a two-dimensional grid pattern with bi-directional communication and a three-dimensional grid pattern with bi-directional communication.
The one directional chain and the 2D grid can be seen in listing \ref{l-mkarray-sample}.

Since the configurations are simply expressed using Python, additional topologies can easily be added.

\lstinputlisting[
  language=python,
  label=l-mkarray-sample,
caption={Chain and grid implementations in \texttt{mkarray}}]
  {mkarray-sample.py}

\section{Result}

%- Communication bandwidth and latency
%- Cycle count for programs
%  - FIR
%  - Fibonacci
%  - vector-matrix multiplication (same as FIR essentially)
%- Size with varying number of fifos
%- Clock rate impact with different number of cores

\subsection{Hardware}

By instantiating a series of bi-directional chains of varying lengths it is possible to determine the scalability of the system.
Figure \ref{fig:bichain-vary-length} shows post place-and-route resource usage and clock period.
As can be observed in the graph, the number of slice registers per core stays constant over the range entire range.
The number of slice LUTs per core goes down slightly as more cores are added, suggesting that the tools are able to share some slice LUTs between cores.
The most significant result, however, is that the clock period increases rapidly with the number of instantiated cores.
Eight cores can run at just under 3 ns, but 64 cores can only run as slowly as somewhat under 4 ns.
This suggests that the tools have great difficulty placing the cores efficiently even at a utilization as low as 20\%.
The critical paths usually come either from the read from the instruction memory or are caused by the large shift operation.
More than 70\% of this delay is caused by routing as opposed to logic.

\begin{figure}
    \caption{Post place-and-route data of bi-directional chains of varying lengths on a Xilinx Virtex 7 \fpgamodel.}
    \label{fig:bichain-vary-length}
    \includegraphics[width=\linewidth]{bichain_vary_length}
\end{figure}

By instantiating the same number of cores but with different topologies, the effect of more communication hardware can be observed.
Figure \ref{fig:comp64} shows performance data of 64 cores in three different configurations.
The graph shows a difference in minimum period of 1 ns between the uni-directional chain and the two-dimensional grid.
Their respective maximum clock frequencies are 292 MHz and 223 MHz.
Eech FIFO added to the processor also approximately 100 slice registers.

\begin{figure}
    \caption{Post place-and-route data of 64 processor cores with different configurations on a Xilinx Virtex 7 \fpgamodel.}
    \label{fig:comp64}
    \includegraphics[width=\linewidth]{comp64}
\end{figure}

\subsection{Software}

Table \ref{t:program-performance} shows size and speed of three programs.
These programs: recursive Fibonacci, recursive factorial and a fixed point FIR filter can be seen in listings \ref{lst:fibonacci}, \ref{lst:factorial} and \ref{lst:fir_filter}, respectively.
The factorial and Fibonacci programs both demonstrate the general compute capabilities of the processor.
The programs show that any recursive program that uses additions, multiplications and conditional branches can be written (as long as it fits in the program memory).
Ubiquitous functions like binary search or bubble sort could therefore be implemented.

The FIR filter program demonstrates the more specialized capabilities of the processor by using the \texttt{CMAC} instruction.
For a filter with a large number of taps, the utilization of the DSP block is very high since it will spend most of its cycles calculating multiply-accumulates.
The program also demonstrates that special purpose hardware can make programs much shorter.
The FIR program is only a quarter of the size of the Fibonacci function, but performs a much more complex function.
Being able to do multiply-accumulates very efficiently is not only good for FIR or IIR filter, but can also be used to perform vector-matrix multiplications, since the calculation is the same at its core.

For an FIR filter with a large number of taps, the computation is dominated by the multiply-accumulate operation.
For a linear chain of 64 cores running at 250 MHz with each processor running a filter with a large number of taps, the effective number of multiply-accumulate operations is 16 billion MACs per second.

One downside of the \texttt{CMAC} instruction is that the implementation requires a significant amount of the area of the Core.
Around 20\% of the area is in fact dedicated to the extra registers, adders and control logic to realise \texttt{CMAC} and \texttt{CSTR}.

\begin{table}
\centering
\caption{Program performance}
\label{t:program-performance}
\newcommand{\const}{\multicolumn{2}{c|}{const}}
\begin{tabular}{| l | l | l | l | l |}
    \hline
    Program     &   Size (num. instr.)  &   Size w/o nops   &   Cycle Count     \\ \hline
    Fibonacci   &   110                 &   24              &   11047 for fib(10)   \\ \hline
    Factorial   &   85                  &   17              &   224 for 4!             \\ \hline
    FIR         &   28                  &   16              &   $13 + numinputs\times(12 + (4 + taps))$ \\ \hline
\end{tabular}
\end{table}

The inter-core communication has a latency of 18 cycles from instruction fetch on the sending processor to register write on the receiving processor.
The sending processor spends six cycles from instruction fetch until the receiving FIFO is written to.
It then takes another six cycles until the FIFO clears its empty-flag.
Finally it takes another six cycles for the data to be read from the FIFO, travel down the pipeline in the receiving processor and be written to the register file.

The bandwidth of the communication is one word per cycle since one send instruction can be issued every cycle.
This is independent on the number of outputs the processor has, since only one can be written to every cycle with the send instruction.
At 330 MHz this is 5.9 gigabits per second per core.
Even at the lowest observed clock frequency of the larger configurations, the bandwidth is 4 gigabits per second per core.
It is, however, safe to say that with increasing number of cores and more complex communication the clock rate will go down and so will the bandwidth.


\section{Discussion}

%- Pipeline too long with no benefit (extra hardware)
%- Low clock frequency
%- Instruction set should be bigger (compare, bitwise ops)
%- More advanced tools
%- Additional adder in order to do more efficient pops

\subsection{Hardware}

Although the processor used the arithmetic operations of the DSP48E1 slice effectively, it did not take advantage of its bitwise operations.
These would have been a useful addition for applications like cryptography where the exclusive-or operation is frequently used.
Another missing feature is a dedicated compare instruction.
The equivalent operation is done using a subtraction and a conditional branch, but by having a compare instruction, a dedicated status register and conditional execution of instructions based on this status register would save up to 7 clock cycles per comparison.
This compare instruction could be implemented using the comparator in the DSP48E1 slice using its pattern detect logic.

As opposed to many modern processors, this design does not have any forwarding paths (short cuts from the output of a data source like the block RAM or DSP block to the their inputs).
The current design could benefit from a forwarding path from the output of the DSP block to the input of the block RAM.
This would save two cycles for memory operations that are dependent on a DSP instruction.
Although this would be of some benefit, it would mean extra area usage to an already too large processor.

The choice to make a multiplication instruction take one more clock cycle was ill-considered since it unnecessarily complicates the write-back logic.
The final implementation also negates any write-back that would have occurred in an instruction following the multiplication.
This problem could easily be alleviated by enabling an extra set of registers in the pre-adder stage of the DSP block (this is done by setting the INMODE input to the appropriate value).

Regarding the decreasing clock frequency with increasing number of cores, it might be an issue with the tools not grouping the processors close enough together which could potentially be solved by manually placing the cores.
It could also be a problem generated by the size of the processor.
By having a smaller core, it would be easier for the tool to pack the processors tightly.

The system presented in this paper is also poorly adapted to the hardware, since many Virtex-7 chips have as little as 400 logic cells per block RAM and as little as 200 logic cells DSP48E1 slice \parencite{virtex7-overview}.
A better architecture would be much smaller, closer to 200 logic cells which is what \cite{cheah2012lean} managed to achieve even though it was not a complete processor.
With the same FIFO based communication, a lot more processors would be possible to instantiate.
Additionally, the ratio between block RAMs and DSP blocks is often 1 to 2 on Virtex-7 chips and an architecture that use two DSP blocks instead of one would utilize the resources better.

\subsection{Software}

The tools created in addition to the processor were useful during the development processes, but would not be considered very good as a product.
The assembler, especially, lacks basic features such as checking the correct operands for a given instruction.
The latest version only fails if the mnemonic is incorrect or more than two operands are given.
This makes it very easy to make mistakes.

Additionally, programming a large number of processor using only the given assembly language is extremely difficult.
Even though the model ensures that a program that reads from the input FIFOs are correct even when the FIFO is empty,
the model is prone to deadlocks if, for example, two processors try to read from each other at the same time.
They will simply lock up, waiting for each other.
A programmer would have to keep these hazards in mind which would make programming very complex.
A better programming language and/or debugging tools that detect these problems would therefore needed.

%- Simultaneous multi threading because nops

\section{Conclusion}

Although this project showed the possibility of creating arrays of DSP block based soft processors on an FPGA,
the resulting hardware was not very well performing overall.
The processor itself uses to many logic cells which inevitable results in poor utilization of block RAMs and DSP blocks.
The FIFO based communication was not very scalable and clock frequency dropped quickly with increasing topology complexity and number of cores in the array.
Several improvements to the processor itself can be made, primarily reducing its size.
If these improvements are made and prove to decrease the size of the processor and increase its clock frequency, a much larger array of processors could be created which could have considerable compute power.

\printbibliography

\pagebreak
\section*{Appendix}

\lstinputlisting[
  label=lst:instruction-set-txt,
caption={Subset of the Core's instruction set in the format used by the opcode generator and the assembler.}]
  {instruction_set_example.txt}

\lstinputlisting[
  label=lst:instruction-set-vhdl,
caption={Subset of the Core's instruction set as a VHDL package generated by \texttt{opcode\_vhdl\_gen} from Listing \ref{lst:instruction-set-txt}}]
  {instruction_set_example.vhd}

\lstinputlisting[
  language=vhdl,
  label=lst:test-template,
caption={Test template generated for \texttt{Core} by \texttt{mktest}}]
  {core_test_template.vhd}

\lstinputlisting[
  label=lst:ping,
caption={Program that decrements a register, sends the result to another processor, receives a piece of data into the same register and loops indefinitely. Companion of program in listing \ref{lst:pong}. Nops removed for consistency.}]
  {twocore.s}

\lstinputlisting[
  label=lst:pong,
caption={Program that receives a piece of data from another processor, decrements the register, sends the result back to the other processor and loops indefinitely. Companion of program in listing \ref{lst:ping}. Nops removed for consistency.}]
  {twocore2.s}

\lstinputlisting[
  label=lst:factorial,
caption={Recursive factorial implementation}]
  {factorial.s}

\lstinputlisting[
  label=lst:fibonacci,
caption={Recursive fibonacci implementation (nops removed for consistency)}]
  {fibonacci.s}

\lstinputlisting[
  label=lst:fir_filter,
caption={Fixed point FIR filter implementation}]
  {fir_filter.s}

\end{document}
